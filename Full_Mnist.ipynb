{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!pip install cleverhans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#\n",
    "## Load MNIST dataset\n",
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "#\n",
    "## Normalize pixel values to range [0, 1]\n",
    "#x_train = x_train.astype('float32') / 255.0\n",
    "#x_test = x_test.astype('float32') / 255.0\n",
    "#\n",
    "## Reshape input data to 4D tensor (batch_size, height, width, channels)\n",
    "#x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "#\n",
    "## Convert labels to categorical one-hot encoding\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "#y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ReLU, GlobalAveragePooling2D, Dense, Lambda\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescentTensorFlowV2\n",
    "from tqdm import tqdm\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from art.utils import load_mnist\n",
    "# Load MNIST dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ReLU, GlobalAveragePooling2D, Dense, Lambda\n",
    "\n",
    "def circular_padding(x, padding_size):\n",
    "    # Perform circular padding on the input tensor\n",
    "    return tf.pad(x, [[0, 0], [padding_size, padding_size], [padding_size, padding_size], [0, 0]], mode='SYMMETRIC')\n",
    "\n",
    "def simple_Conv(n_hidden, kernel_size=28, padding_size=-1):\n",
    "    if padding_size == -1:\n",
    "        padding_size = kernel_size // 2\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: circular_padding(x, padding_size), input_shape=(28, 28, 1)))\n",
    "    model.add(Conv2D(n_hidden, kernel_size=kernel_size, padding='valid'))\n",
    "    model.add(ReLU())\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(10))\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "n_hidden = 1000\n",
    "padding_sizes = [0,2,4,6,8,10,12,14]\n",
    "padding_size = padding_sizes[5]\n",
    "# padding_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# https://github.com/Trusted-AI/adversarial-robustness-toolbox/discussions/1288\n",
    "# we use the solution from the link above\n",
    "\n",
    "def train_step(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "        #SparseCategoricalCrossentropy\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "## Create TensorFlowV2Classifier\n",
    "#model = simple_Conv(n_hidden, kernel_size=28, padding_size=padding_size)\n",
    "#model.compile(optimizer=tf.keras.optimizers.legacy.SGD(learning_rate=0.1, momentum=0.9, decay=5e-4),\n",
    "#              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "#              metrics=['accuracy'])\n",
    "## CategoricalCrossentropy # SparseCategoricalCrossentropy\n",
    "#classifier = TensorFlowV2Classifier(\n",
    "#    model=model,\n",
    "#    nb_classes=10,\n",
    "#    input_shape=(28, 28, 1),\n",
    "#    clip_values=(0, 1),\n",
    "#    train_step=train_step\n",
    "#)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = simple_Conv(n_hidden, kernel_size=28, padding_size=padding_size)\n",
    "#model.compile(optimizer=tf.keras.optimizers.legacy.SGD(learning_rate=0.1, momentum=0.9, decay=5e-4),\n",
    "#              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "#              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.1, momentum=0.9, decay=5e-4)\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Step 3: Create the ART classifier\n",
    "\n",
    "classifier = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    loss_object=loss_object,\n",
    "    train_step=train_step,\n",
    "    nb_classes=10,\n",
    "    input_shape=(28, 28, 1),\n",
    "    clip_values=(0, 1),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 4: Train the ART classifier\n",
    "\n",
    "classifier_history = classifier.fit(x_train, y_train, batch_size=64, nb_epochs=3,verbose=2)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done\n"
     ]
    }
   ],
   "source": [
    "print(\"training done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 96.06%\n"
     ]
    }
   ],
   "source": [
    "## Evaluate on clean test examples\n",
    "#_, accuracy = classifier.evaluate(x_test, y_test)\n",
    "#print(\"Accuracy on clean test examples: {:.2f}%\".format(accuracy * 100))\n",
    "# Step 5: Evaluate the ART classifier on benign test examples\n",
    "\n",
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
    "# # Evaluate on clean test examples\n",
    "# predictions = np.argmax(classifier.predict(x_test), axis=1)\n",
    "# accuracy = np.sum(predictions == y_test) / len(y_test)\n",
    "# print(\"Accuracy on clean test examples: {:.2f}%\".format(accuracy * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescentTensorFlowV2\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "# limited example\n",
    "#attack_params = [ [np.inf, [ 0.1]] ,[2, [ 1.5]]]\n",
    "attack_params = [[2, [0.5, 1, 1.5, 2, 2.5]], [np.inf, [0.05, 0.1, 0.15, 0.2, 0.25]]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "tqdm._instances.clear()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating Adversarial Examples (Train):   0%|          | 0/60000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08fc3b12c85049f0a8a824e3e1745ad0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "PGD - Batches: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd6131569d784bc4941d650d0abb5153"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "PGD - Batches: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30bfc702052b441b9b61339aa1a25469"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "PGD - Batches: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32dcd6f3d59549418e7d7553877cfdfc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "PGD - Batches: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea62c5a59e0741b2ab8ab2937ad281c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [34]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mzip\u001B[39m(x_train, y_train), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(y_train), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating Adversarial Examples (Train)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     21\u001B[0m     x_np \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(x)  \u001B[38;5;66;03m# Convert x to a NumPy array\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m     x_adv \u001B[38;5;241m=\u001B[39m \u001B[43mattack\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand_dims\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_np\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m     x_train_attack\u001B[38;5;241m.\u001B[39mappend(x_adv[\u001B[38;5;241m0\u001B[39m])  \u001B[38;5;66;03m# Convert EagerTensor to NumPy array\u001B[39;00m\n\u001B[0;32m     24\u001B[0m     y_train_attack\u001B[38;5;241m.\u001B[39mappend(y)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\art\\attacks\\evasion\\projected_gradient_descent\\projected_gradient_descent_tensorflow_v2.py:190\u001B[0m, in \u001B[0;36mProjectedGradientDescentTensorFlowV2.generate\u001B[1;34m(self, x, y, **kwargs)\u001B[0m\n\u001B[0;32m    186\u001B[0m data_loader \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(dataset)\n\u001B[0;32m    188\u001B[0m \u001B[38;5;66;03m# Compute perturbation with batching\u001B[39;00m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (batch_id, batch_all) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\n\u001B[1;32m--> 190\u001B[0m     \u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPGD - Batches\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mleave\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    191\u001B[0m ):\n\u001B[0;32m    193\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_id \u001B[38;5;241m=\u001B[39m batch_id\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tqdm\\notebook.py:247\u001B[0m, in \u001B[0;36mtqdm_notebook.__init__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdisplayed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m display_here \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelay \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 247\u001B[0m     \u001B[43mdisplay\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontainer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdisplayed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdisp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdisplay\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\display_functions.py:305\u001B[0m, in \u001B[0;36mdisplay\u001B[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001B[0m\n\u001B[0;32m    302\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m metadata:\n\u001B[0;32m    303\u001B[0m             \u001B[38;5;66;03m# kwarg-specified metadata gets precedence\u001B[39;00m\n\u001B[0;32m    304\u001B[0m             _merge(md_dict, metadata)\n\u001B[1;32m--> 305\u001B[0m         publish_display_data(data\u001B[38;5;241m=\u001B[39mformat_dict, metadata\u001B[38;5;241m=\u001B[39mmd_dict, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    306\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m display_id:\n\u001B[0;32m    307\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DisplayHandle(display_id)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\display_functions.py:93\u001B[0m, in \u001B[0;36mpublish_display_data\u001B[1;34m(data, metadata, source, transient, **kwargs)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transient:\n\u001B[0;32m     91\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtransient\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m transient\n\u001B[1;32m---> 93\u001B[0m display_pub\u001B[38;5;241m.\u001B[39mpublish(\n\u001B[0;32m     94\u001B[0m     data\u001B[38;5;241m=\u001B[39mdata,\n\u001B[0;32m     95\u001B[0m     metadata\u001B[38;5;241m=\u001B[39mmetadata,\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m     97\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py:102\u001B[0m, in \u001B[0;36mZMQDisplayPublisher.publish\u001B[1;34m(self, data, metadata, transient, update)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpublish\u001B[39m(\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     82\u001B[0m     data,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     85\u001B[0m     update\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     86\u001B[0m ):\n\u001B[0;32m     87\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Publish a display-data message\u001B[39;00m\n\u001B[0;32m     88\u001B[0m \n\u001B[0;32m     89\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;124;03m        If True, send an update_display_data message instead of display_data.\u001B[39;00m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 102\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flush_streams\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m metadata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    104\u001B[0m         metadata \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py:65\u001B[0m, in \u001B[0;36mZMQDisplayPublisher._flush_streams\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_flush_streams\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     64\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"flush IO Streams prior to display\"\"\"\u001B[39;00m\n\u001B[1;32m---> 65\u001B[0m     \u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflush\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m     sys\u001B[38;5;241m.\u001B[39mstderr\u001B[38;5;241m.\u001B[39mflush()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\iostream.py:475\u001B[0m, in \u001B[0;36mOutStream.flush\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    464\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"trigger actual zmq send\u001B[39;00m\n\u001B[0;32m    465\u001B[0m \n\u001B[0;32m    466\u001B[0m \u001B[38;5;124;03msend will happen in the background thread\u001B[39;00m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    468\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    469\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_thread\n\u001B[0;32m    470\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_thread\u001B[38;5;241m.\u001B[39mthread \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    473\u001B[0m ):\n\u001B[0;32m    474\u001B[0m     \u001B[38;5;66;03m# request flush on the background thread\u001B[39;00m\n\u001B[1;32m--> 475\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpub_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschedule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flush\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    476\u001B[0m     \u001B[38;5;66;03m# wait for flush to actually get through, if we can.\u001B[39;00m\n\u001B[0;32m    477\u001B[0m     evt \u001B[38;5;241m=\u001B[39m threading\u001B[38;5;241m.\u001B[39mEvent()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\iostream.py:210\u001B[0m, in \u001B[0;36mIOPubThread.schedule\u001B[1;34m(self, f)\u001B[0m\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_events\u001B[38;5;241m.\u001B[39mappend(f)\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;66;03m# wake event thread (message content is ignored)\u001B[39;00m\n\u001B[1;32m--> 210\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event_pipe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    211\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    212\u001B[0m     f()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\zmq\\sugar\\socket.py:618\u001B[0m, in \u001B[0;36mSocket.send\u001B[1;34m(self, data, flags, copy, track, routing_id, group)\u001B[0m\n\u001B[0;32m    611\u001B[0m         data \u001B[38;5;241m=\u001B[39m zmq\u001B[38;5;241m.\u001B[39mFrame(\n\u001B[0;32m    612\u001B[0m             data,\n\u001B[0;32m    613\u001B[0m             track\u001B[38;5;241m=\u001B[39mtrack,\n\u001B[0;32m    614\u001B[0m             copy\u001B[38;5;241m=\u001B[39mcopy \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    615\u001B[0m             copy_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy_threshold,\n\u001B[0;32m    616\u001B[0m         )\n\u001B[0;32m    617\u001B[0m     data\u001B[38;5;241m.\u001B[39mgroup \u001B[38;5;241m=\u001B[39m group\n\u001B[1;32m--> 618\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrack\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrack\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mzmq\\backend\\cython\\socket.pyx:740\u001B[0m, in \u001B[0;36mzmq.backend.cython.socket.Socket.send\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mzmq\\backend\\cython\\socket.pyx:787\u001B[0m, in \u001B[0;36mzmq.backend.cython.socket.Socket.send\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mzmq\\backend\\cython\\socket.pyx:244\u001B[0m, in \u001B[0;36mzmq.backend.cython.socket._send_copy\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001B[0m, in \u001B[0;36mzmq.backend.cython.checkrc._check_rc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#from tqdm.auto import tqdm\n",
    "#\n",
    "##attack_params = [[2, [0.5, 1, 1.5, 2, 2.5]], [np.inf, [0.05, 0.1, 0.15, 0.2, 0.25]]]\n",
    "#\n",
    "#for norm, epsilons in attack_params:\n",
    "#    for epsilon in epsilons:\n",
    "#        if norm == 2:\n",
    "#            attack = FastGradientMethod(estimator=classifier, eps=epsilon, norm=norm)\n",
    "#        else:\n",
    "#            attack = ProjectedGradientDescentTensorFlowV2(estimator=classifier, eps=epsilon, norm=norm)\n",
    "#        print(norm, epsilon)\n",
    "#        adv_correct = 0\n",
    "#        adv_loss = 0\n",
    "#        total = 0\n",
    "#        x_train_attack = []\n",
    "#        y_train_attack = []\n",
    "#        x_test_attack = []\n",
    "#        y_test_attack = []\n",
    "#\n",
    "#        for x, y in tqdm(zip(x_train, y_train), total=len(y_train), desc=\"Generating Adversarial Examples (Train)\"):\n",
    "#            x_np = np.array(x)  # Convert x to a NumPy array\n",
    "#            x_adv = attack.generate(x=np.expand_dims(x_np, axis=0))\n",
    "#            x_train_attack.append(x_adv[0])  # Convert EagerTensor to NumPy array\n",
    "#            y_train_attack.append(y)\n",
    "#\n",
    "#        for x, y in tqdm(zip(x_test, y_test), total=len(y_test), desc=\"Generating Adversarial Examples (Test)\"):\n",
    "#            x_np = np.array(x)  # Convert x to a NumPy array\n",
    "#            x_adv = attack.generate(x=np.expand_dims(x_np, axis=0))\n",
    "#            x_test_attack.append(x_adv[0])  # Convert EagerTensor to NumPy array\n",
    "#            y_test_attack.append(y)\n",
    "#\n",
    "#        # Convert to numpy arrays\n",
    "#        x_train_attack = np.array(x_train_attack)\n",
    "#        y_train_attack = np.array(y_train_attack)\n",
    "#        x_test_attack = np.array(x_test_attack)\n",
    "#        y_test_attack = np.array(y_test_attack)\n",
    "#\n",
    "#        # Save the adversarial data\n",
    "#        attack_name = attack.__class__.__name__\n",
    "#        model_name = \"simple_Conv_28_10_1000\"  # Update with the appropriate model name\n",
    "#        save_dir = \"adversarial_data\"\n",
    "#        os.makedirs(save_dir, exist_ok=True)\n",
    "#        np.savez(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}_train.npz\"), x_train_attack=x_train_attack, y_train_attack=y_train_attack)\n",
    "#        np.savez(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}_test.npz\"), x_test_attack=x_test_attack, y_test_attack=y_test_attack)\n",
    "#\n",
    "#        print(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}\"))\n",
    "#\n",
    "#        # Calculate accuracy and loss\n",
    "#        for x, y in tqdm(zip(x_test_attack, y_test_attack), total=len(y_test_attack), desc=\"Evaluating Adversarial Examples\"):\n",
    "#            predictions_adv = np.argmax(classifier.predict(np.expand_dims(x, axis=0)), axis=1)\n",
    "#            adv_correct += (predictions_adv == y).sum()\n",
    "#            total += 1\n",
    "#\n",
    "#        _, adv_loss = classifier.model.evaluate(x_test_attack, y_test_attack, verbose=0)\n",
    "#        accuracy = adv_correct / total\n",
    "#        print(\"Accuracy on adversarial test examples (L_{:.0f}, eps={:.2f}): {:.2f}%. Loss: {:.2f}\".format(norm, epsilon, accuracy * 100, adv_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf 0.1\n",
      "Generating Adversarial Examples (Train) simple_Conv_28_10_1000_ProjectedGradientDescentTensorFlowV2_0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": "PGD - Batches: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a753ae19d1042f38bd68e8ad93a4cc7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Conv2DBackpropFilter_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[6,441,784] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Conv2DBackpropFilter]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Input \u001B[1;32mIn [35]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     20\u001B[0m y_test_attack \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating Adversarial Examples (Train) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattack_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepsilon\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 22\u001B[0m x_train_attack \u001B[38;5;241m=\u001B[39m \u001B[43mattack\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m y_train_attack \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mcopy(y_train)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m( \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating Adversarial Examples (Test) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattack_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepsilon\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\art\\attacks\\evasion\\projected_gradient_descent\\projected_gradient_descent_tensorflow_v2.py:219\u001B[0m, in \u001B[0;36mProjectedGradientDescentTensorFlowV2.generate\u001B[1;34m(self, x, y, **kwargs)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m rand_init_num \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_random_init)):\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m rand_init_num \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;66;03m# first iteration: use the adversarial examples as they are the only ones we have now\u001B[39;00m\n\u001B[1;32m--> 219\u001B[0m         adv_x[batch_index_1:batch_index_2] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_batch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    220\u001B[0m \u001B[43m            \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_eps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_eps_step\u001B[49m\n\u001B[0;32m    221\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    222\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    223\u001B[0m         adversarial_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_batch(\n\u001B[0;32m    224\u001B[0m             x\u001B[38;5;241m=\u001B[39mbatch, targets\u001B[38;5;241m=\u001B[39mbatch_labels, mask\u001B[38;5;241m=\u001B[39mmask_batch, eps\u001B[38;5;241m=\u001B[39mbatch_eps, eps_step\u001B[38;5;241m=\u001B[39mbatch_eps_step\n\u001B[0;32m    225\u001B[0m         )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\art\\attacks\\evasion\\projected_gradient_descent\\projected_gradient_descent_tensorflow_v2.py:274\u001B[0m, in \u001B[0;36mProjectedGradientDescentTensorFlowV2._generate_batch\u001B[1;34m(self, x, targets, mask, eps, eps_step)\u001B[0m\n\u001B[0;32m    272\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i_max_iter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_iter):\n\u001B[0;32m    273\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_i_max_iter \u001B[38;5;241m=\u001B[39m i_max_iter\n\u001B[1;32m--> 274\u001B[0m     adv_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_tf\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[43madv_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_random_init\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi_max_iter\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m adv_x\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\art\\attacks\\evasion\\projected_gradient_descent\\projected_gradient_descent_tensorflow_v2.py:441\u001B[0m, in \u001B[0;36mProjectedGradientDescentTensorFlowV2._compute_tf\u001B[1;34m(self, x, x_init, y, mask, eps, eps_step, momentum, random_init)\u001B[0m\n\u001B[0;32m    438\u001B[0m     x_adv \u001B[38;5;241m=\u001B[39m x\n\u001B[0;32m    440\u001B[0m \u001B[38;5;66;03m# Get perturbation\u001B[39;00m\n\u001B[1;32m--> 441\u001B[0m perturbation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_perturbation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_adv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecay\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[38;5;66;03m# Apply perturbation and clip\u001B[39;00m\n\u001B[0;32m    444\u001B[0m x_adv \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_perturbation(x_adv, perturbation, eps_step)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\art\\attacks\\evasion\\projected_gradient_descent\\projected_gradient_descent_tensorflow_v2.py:316\u001B[0m, in \u001B[0;36mProjectedGradientDescentTensorFlowV2._compute_perturbation\u001B[1;34m(self, x, y, mask, decay, momentum)\u001B[0m\n\u001B[0;32m    313\u001B[0m tol \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10e-8\u001B[39m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;66;03m# Get gradient wrt loss; invert it if attack is targeted\u001B[39;00m\n\u001B[1;32m--> 316\u001B[0m grad: tf\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_gradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mconstant(\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtargeted), dtype\u001B[38;5;241m=\u001B[39mART_NUMPY_DTYPE\n\u001B[0;32m    318\u001B[0m )\n\u001B[0;32m    320\u001B[0m \u001B[38;5;66;03m# Write summary\u001B[39;00m\n\u001B[0;32m    321\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msummary_writer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\art\\estimators\\classification\\tensorflow.py:1214\u001B[0m, in \u001B[0;36mTensorFlowV2Classifier.loss_gradient\u001B[1;34m(self, x, y, training_mode, **kwargs)\u001B[0m\n\u001B[0;32m   1211\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1212\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loss_object(y_input, predictions)\n\u001B[1;32m-> 1214\u001B[0m gradients \u001B[38;5;241m=\u001B[39m \u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_grad\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1216\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m   1217\u001B[0m     gradients \u001B[38;5;241m=\u001B[39m gradients\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1063\u001B[0m, in \u001B[0;36mGradientTape.gradient\u001B[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[0;32m   1057\u001B[0m   output_gradients \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1058\u001B[0m       composite_tensor_gradient\u001B[38;5;241m.\u001B[39mget_flat_tensors_for_gradients(\n\u001B[0;32m   1059\u001B[0m           output_gradients))\n\u001B[0;32m   1060\u001B[0m   output_gradients \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(x)\n\u001B[0;32m   1061\u001B[0m                       \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m output_gradients]\n\u001B[1;32m-> 1063\u001B[0m flat_grad \u001B[38;5;241m=\u001B[39m \u001B[43mimperative_grad\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimperative_grad\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1064\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1065\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_targets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1066\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_sources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1067\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_gradients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1068\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources_raw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflat_sources_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1069\u001B[0m \u001B[43m    \u001B[49m\u001B[43munconnected_gradients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munconnected_gradients\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1071\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent:\n\u001B[0;32m   1072\u001B[0m   \u001B[38;5;66;03m# Keep track of watched variables before setting tape to None\u001B[39;00m\n\u001B[0;32m   1073\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_watched_variables \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tape\u001B[38;5;241m.\u001B[39mwatched_variables()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001B[0m, in \u001B[0;36mimperative_grad\u001B[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m     64\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     65\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown value for unconnected_gradients: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m unconnected_gradients)\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_TapeGradient\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m     69\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43munconnected_gradients\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:146\u001B[0m, in \u001B[0;36m_gradient_function\u001B[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[0;32m    144\u001B[0m     gradient_name_scope \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m forward_pass_name_scope \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    145\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mname_scope(gradient_name_scope):\n\u001B[1;32m--> 146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgrad_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmock_op\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mout_grads\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    148\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m grad_fn(mock_op, \u001B[38;5;241m*\u001B[39mout_grads)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py:592\u001B[0m, in \u001B[0;36m_Conv2DGrad\u001B[1;34m(op, grad)\u001B[0m\n\u001B[0;32m    573\u001B[0m shape_0, shape_1 \u001B[38;5;241m=\u001B[39m array_ops\u001B[38;5;241m.\u001B[39mshape_n([op\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m0\u001B[39m], op\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m1\u001B[39m]])\n\u001B[0;32m    575\u001B[0m \u001B[38;5;66;03m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001B[39;00m\n\u001B[0;32m    576\u001B[0m \u001B[38;5;66;03m# functions for performance reasons in Eager mode. gen_nn_ops functions take a\u001B[39;00m\n\u001B[0;32m    577\u001B[0m \u001B[38;5;66;03m# `explicit_paddings` parameter, but nn_ops functions do not. So if we were\u001B[39;00m\n\u001B[0;32m    578\u001B[0m \u001B[38;5;66;03m# to use the nn_ops functions, we would have to convert `padding` and\u001B[39;00m\n\u001B[0;32m    579\u001B[0m \u001B[38;5;66;03m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001B[39;00m\n\u001B[0;32m    580\u001B[0m \u001B[38;5;66;03m# in Eager mode.\u001B[39;00m\n\u001B[0;32m    581\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m    582\u001B[0m     gen_nn_ops\u001B[38;5;241m.\u001B[39mconv2d_backprop_input(\n\u001B[0;32m    583\u001B[0m         shape_0,\n\u001B[0;32m    584\u001B[0m         op\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m1\u001B[39m],\n\u001B[0;32m    585\u001B[0m         grad,\n\u001B[0;32m    586\u001B[0m         dilations\u001B[38;5;241m=\u001B[39mdilations,\n\u001B[0;32m    587\u001B[0m         strides\u001B[38;5;241m=\u001B[39mstrides,\n\u001B[0;32m    588\u001B[0m         padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m    589\u001B[0m         explicit_paddings\u001B[38;5;241m=\u001B[39mexplicit_paddings,\n\u001B[0;32m    590\u001B[0m         use_cudnn_on_gpu\u001B[38;5;241m=\u001B[39muse_cudnn_on_gpu,\n\u001B[0;32m    591\u001B[0m         data_format\u001B[38;5;241m=\u001B[39mdata_format),\n\u001B[1;32m--> 592\u001B[0m     \u001B[43mgen_nn_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d_backprop_filter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    594\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshape_1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdilations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdilations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    597\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    598\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    599\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexplicit_paddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexplicit_paddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    600\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cudnn_on_gpu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cudnn_on_gpu\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    601\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    602\u001B[0m ]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:1376\u001B[0m, in \u001B[0;36mconv2d_backprop_filter\u001B[1;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001B[0m\n\u001B[0;32m   1374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   1375\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 1376\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1377\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n\u001B[0;32m   1378\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7262\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   7260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[0;32m   7261\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 7262\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: {{function_node __wrapped__Conv2DBackpropFilter_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[6,441,784] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Conv2DBackpropFilter]"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "#attack_params = [[2, [0.5, 1, 1.5, 2, 2.5]], [np.inf, [0.05, 0.1, 0.15, 0.2, 0.25]]]\n",
    "\n",
    "for norm, epsilons in attack_params:\n",
    "    for epsilon in epsilons:\n",
    "        if norm == 2:\n",
    "            attack = FastGradientMethod(estimator=classifier, eps=epsilon, norm=norm)\n",
    "        else:\n",
    "            attack = ProjectedGradientDescentTensorFlowV2(estimator=classifier, eps=epsilon, norm=norm)\n",
    "        print(norm, epsilon)\n",
    "        attack_name = attack.__class__.__name__\n",
    "        model_name = \"simple_Conv_28_10_1000\"  # Update with the appropriate model name\n",
    "        adv_correct = 0\n",
    "        adv_loss = 0\n",
    "        total = 0\n",
    "        x_train_attack = []\n",
    "        y_train_attack = []\n",
    "        x_test_attack = []\n",
    "        y_test_attack = []\n",
    "        print(f\"Generating Adversarial Examples (Train) {model_name}_{attack_name}_{epsilon}\")\n",
    "        x_train_attack = attack.generate(x=x_train)\n",
    "        y_train_attack = np.copy(y_train)\n",
    "\n",
    "        print( f\"Generating Adversarial Examples (Test) {model_name}_{attack_name}_{epsilon}\")\n",
    "        x_test_attack = attack.generate(x=x_test)\n",
    "        y_test_attack = np.copy(y_test)\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        x_train_attack = np.array(x_train_attack)\n",
    "        y_train_attack = np.array(y_train_attack)\n",
    "        x_test_attack = np.array(x_test_attack)\n",
    "        y_test_attack = np.array(y_test_attack)\n",
    "\n",
    "        # Save the adversarial data\n",
    "\n",
    "        save_dir = \"adversarial_data\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        np.savez(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}_train.npz\"), x_train_attack=x_train_attack, y_train_attack=y_train_attack)\n",
    "        np.savez(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}_test.npz\"), x_test_attack=x_test_attack, y_test_attack=y_test_attack)\n",
    "\n",
    "        print(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}\"))\n",
    "\n",
    "        # Calculate accuracy and loss\n",
    "        for x, y in tqdm(zip(x_test_attack, y_test_attack), total=len(y_test_attack), desc=\"Evaluating Adversarial Examples\"):\n",
    "            predictions_adv = p.argmax(classifier.predict(np.expand_dims(x, axis=0)), axis=1)\n",
    "            adv_correct += (predictions_adv == y).sum()\n",
    "            total += 1\n",
    "\n",
    "        _, adv_loss = classifier.model.evaluate(x_test_attack, y_test_attack, verbose=0)\n",
    "        accuracy = adv_correct / total\n",
    "        print(\"Accuracy on adversarial test examples (L_{:.0f}, eps={:.2f}): {:.2f}%. Loss: {:.2f}\".format(norm, epsilon, accuracy * 100, adv_loss))n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "#_, adv_loss = classifier.model.evaluate(x_test_attack, y_test_attack, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}