{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Orthogonal Vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Activation, Conv1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from art.attacks.evasion import ProjectedGradientDescentL2, DeepFool\n",
    "from art.metrics import empirical_robustness\n",
    "from art.defences.trainer import AdversarialTrainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_neural_net(input_size, hidden_layers, hidden_size, num_classes, no_final=False):\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(input_size,)))\n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(Dense(hidden_size))\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(Dense(num_classes))\n",
    "    if not no_final:\n",
    "        model.add(Activation('tanh'))\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def create_cnn_one_d(hidden_channels=1024, kernel_size=5, num_classes=1, padding='same', no_final=False):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(hidden_channels, kernel_size, padding=padding))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(num_classes))\n",
    "    if not no_final:\n",
    "        model.add(Activation('tanh'))\n",
    "    return model\n",
    "\n",
    "def train_model(model, data, labels, epochs=1000):\n",
    "    model.compile(optimizer=Adam(lr=1e-2), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(data, labels, batch_size=data.shape[0], epochs=epochs)\n",
    "    return model\n",
    "\n",
    "def test_pgd(model, data, labels, epsilon, res_row):\n",
    "    attack = ProjectedGradientDescentL2(estimator=model, eps=epsilon, eps_step=epsilon/50, max_iter=100)\n",
    "    perturbed_data = attack.generate(x=data, y=labels)\n",
    "    new_out = model(perturbed_data)\n",
    "    pred = tf.argmax(new_out, axis=1)\n",
    "    correct = tf.reduce_sum(tf.cast(tf.equal(pred, labels), tf.float32))\n",
    "    res_row.append(100 * correct / labels.shape[0])\n",
    "\n",
    "def test_deepfool(model, data, labels, res_row):\n",
    "    attack = DeepFool(estimator=model)\n",
    "    perturbed_data = attack.generate(x=data, y=labels)\n",
    "    new_out = model(perturbed_data)\n",
    "    pred = tf.argmax(new_out, axis=1)\n",
    "    correct = tf.reduce_sum(tf.cast(tf.equal(pred, labels), tf.float32))\n",
    "    res_row.append(100 * correct / labels.shape[0])\n",
    "\n",
    "def add_linear_separator(d1, d2, p):\n",
    "    z_1 = np.mean(d1, axis=0)\n",
    "    z_2 = np.mean(d2, axis=0)\n",
    "    z_1 /= np.linalg.norm(z_1)\n",
    "    z_2 /= np.linalg.norm(z_2)\n",
    "\n",
    "    d1_n = z_1 * p + d1 * (1 - p)\n",
    "    d2_n = z_2 * p + d2 * (1 - p)\n",
    "    d1_n /= np.expand_dims(np.linalg.norm(d1_n, axis=1), 1)\n",
    "    d2_n /= np.expand_dims(np.linalg.norm(d2_n, axis=1), 1)\n",
    "    return d1_n, d2_n\n",
    "\n",
    "def sample_orth_datasets(dimension, samples, p):\n",
    "    if p < 0:\n",
    "        d1, d2 = x[:k], x[dimension//2:dimension//2+samples]\n",
    "    else:\n",
    "        d1, d2 = x[:k], x[dimension//2:dimension//2+samples]\n",
    "        z1, z2 = x[k-1], x[dimension//2+samples-1]\n",
    "        d1 = d1 + z1 * p\n",
    "        d2 = d2 + z2 * p\n",
    "    return d1, d2\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}