{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!pip install cleverhans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#\n",
    "## Load MNIST dataset\n",
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "#\n",
    "## Normalize pixel values to range [0, 1]\n",
    "#x_train = x_train.astype('float32') / 255.0\n",
    "#x_test = x_test.astype('float32') / 255.0\n",
    "#\n",
    "## Reshape input data to 4D tensor (batch_size, height, width, channels)\n",
    "#x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "#\n",
    "## Convert labels to categorical one-hot encoding\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "#y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ReLU, GlobalAveragePooling2D, Dense, Lambda\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescentTensorFlowV2\n",
    "from tqdm import tqdm\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from art.utils import load_mnist\n",
    "# Load MNIST dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "\n",
    "def circular_padding(x, padding_size):\n",
    "    # Perform circular padding on the input\n",
    "    return tf.pad(x, [[0, 0], [padding_size, padding_size], [padding_size, padding_size], [0, 0]], mode='SYMMETRIC')\n",
    "\n",
    "def simple_Conv(n_hidden, kernel_size=28, padding_size=-1):\n",
    "    if padding_size == -1:\n",
    "        padding_size = kernel_size // 2\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: circular_padding(x, padding_size), input_shape=(28, 28, 1)))\n",
    "    model.add(Conv2D(n_hidden, kernel_size=kernel_size, padding='valid'))\n",
    "    model.add(ReLU())\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(10))\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "n_hidden = 1000\n",
    "padding_sizes = [0,2,4,6,8,10,12,14]\n",
    "padding_size = padding_sizes[5]\n",
    "# padding_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# https://github.com/Trusted-AI/adversarial-robustness-toolbox/discussions/1288\n",
    "# we use the solution from the link above\n",
    "\n",
    "def train_step(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "        #SparseCategoricalCrossentropy\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(None, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"lambda_3/MirrorPad:0\", shape=(None, 48, 48, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = simple_Conv(n_hidden, kernel_size=28, padding_size=padding_size)\n",
    "#model.compile(optimizer=tf.keras.optimizers.legacy.SGD(learning_rate=0.1, momentum=0.9, decay=5e-4),\n",
    "#              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "#              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "#optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.1, momentum=0.9, decay=5e-4)\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_object,\n",
    "              metrics=['accuracy'])\n",
    "# Step 3: Create the ART classifier\n",
    "\n",
    "classifier = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    loss_object=loss_object,\n",
    "    train_step=train_step,\n",
    "    nb_classes=10,\n",
    "    input_shape=(28, 28, 1),\n",
    "    clip_values=(0, 1),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "\n",
    "## Create TensorFlowV2Classifier\n",
    "#model = simple_Conv(n_hidden, kernel_size=28, padding_size=padding_size)\n",
    "#model.compile(optimizer=tf.keras.optimizers.legacy.SGD(learning_rate=0.1, momentum=0.9, decay=5e-4),\n",
    "#              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "#              metrics=['accuracy'])\n",
    "## CategoricalCrossentropy # SparseCategoricalCrossentropy\n",
    "#classifier = TensorFlowV2Classifier(\n",
    "#    model=model,\n",
    "#    nb_classes=10,\n",
    "#    input_shape=(28, 28, 1),\n",
    "#    clip_values=(0, 1),\n",
    "#    train_step=train_step\n",
    "#)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 4: Train the ART classifier\n",
    "\n",
    "classifier_history = classifier.fit(x_train, y_train, batch_size=64, nb_epochs=3,verbose=2)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done\n"
     ]
    }
   ],
   "source": [
    "print(\"training done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test examples: 96.0%\n"
     ]
    }
   ],
   "source": [
    "## Evaluate on clean test examples\n",
    "#_, accuracy = classifier.evaluate(x_test, y_test)\n",
    "#print(\"Accuracy on clean test examples: {:.2f}%\".format(accuracy * 100))\n",
    "# Step 5: Evaluate the ART classifier on benign test examples\n",
    "\n",
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on test examples: {}%\".format(accuracy * 100))\n",
    "# # Evaluate on clean test examples\n",
    "# predictions = np.argmax(classifier.predict(x_test), axis=1)\n",
    "# accuracy = np.sum(predictions == y_test) / len(y_test)\n",
    "# print(\"Accuracy on clean test examples: {:.2f}%\".format(accuracy * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train examples: 95.72666666666667%\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(x_train)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_train, axis=1)) / len(y_train)\n",
    "print(\"Accuracy on train examples: {}%\".format(accuracy * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescentTensorFlowV2\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "# limited example\n",
    "#attack_params = [ [np.inf, [ 0.1]] ,[2, [ 1.5]]]\n",
    "attack_params = [[2, [0.5, 1, 1.5, 2, 2.5]], [np.inf, [0.05, 0.1, 0.15, 0.2, 0.25]]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "tqdm._instances.clear()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Adversarial Examples (Train): 100%|██████████| 60000/60000 [47:36<00:00, 21.01it/s]\n",
      "Generating Adversarial Examples (Test): 100%|██████████| 10000/10000 [07:59<00:00, 20.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversarial_data\\simple_Conv_28_10_1000_FastGradientMethod_0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Adversarial Examples: 100%|██████████| 10000/10000 [01:59<00:00, 84.03it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [36]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     51\u001B[0m     adv_correct \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (predictions_adv \u001B[38;5;241m==\u001B[39m y)\u001B[38;5;241m.\u001B[39msum()\n\u001B[0;32m     52\u001B[0m     total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m---> 54\u001B[0m _, adv_loss \u001B[38;5;241m=\u001B[39m \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_test_attack\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test_attack\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m adv_correct \u001B[38;5;241m/\u001B[39m total\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy on adversarial test examples (L_\u001B[39m\u001B[38;5;132;01m{:.0f}\u001B[39;00m\u001B[38;5;124m, eps=\u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m. Loss: \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(norm, epsilon, accuracy \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m, adv_loss))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\keras\\engine\\training.py:3685\u001B[0m, in \u001B[0;36mModel._assert_compile_was_called\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   3679\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_assert_compile_was_called\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   3680\u001B[0m     \u001B[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001B[39;00m\n\u001B[0;32m   3681\u001B[0m     \u001B[38;5;66;03m# then the optimizer is set. This is different from whether the\u001B[39;00m\n\u001B[0;32m   3682\u001B[0m     \u001B[38;5;66;03m# model is compiled\u001B[39;00m\n\u001B[0;32m   3683\u001B[0m     \u001B[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001B[39;00m\n\u001B[0;32m   3684\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_compiled:\n\u001B[1;32m-> 3685\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   3686\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou must compile your model before \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3687\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining/testing. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3688\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse `model.compile(optimizer, loss)`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3689\u001B[0m         )\n",
      "\u001B[1;31mRuntimeError\u001B[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "#from tqdm.auto import tqdm\n",
    "\n",
    "attack_params = [[2, [0.5, 1, 1.5, 2, 2.5]]]\n",
    "\n",
    "for norm, epsilons in attack_params:\n",
    "    for epsilon in epsilons:\n",
    "        if norm == 2:\n",
    "            attack = FastGradientMethod(estimator=classifier, eps=epsilon, norm=norm)\n",
    "        else:\n",
    "            attack = ProjectedGradientDescentTensorFlowV2(estimator=classifier, eps=epsilon, norm=norm)\n",
    "        print(norm, epsilon)\n",
    "        adv_correct = 0\n",
    "        adv_loss = 0\n",
    "        total = 0\n",
    "        x_train_attack = []\n",
    "        y_train_attack = []\n",
    "        x_test_attack = []\n",
    "        y_test_attack = []\n",
    "\n",
    "        for x, y in tqdm(zip(x_train, y_train), total=len(y_train), desc=\"Generating Adversarial Examples (Train)\"):\n",
    "            x_np = np.array(x)  # Convert x to a NumPy array\n",
    "            x_adv = attack.generate(x=np.expand_dims(x_np, axis=0))\n",
    "            x_train_attack.append(x_adv[0])  # Convert EagerTensor to NumPy array\n",
    "            y_train_attack.append(y)\n",
    "\n",
    "        for x, y in tqdm(zip(x_test, y_test), total=len(y_test), desc=\"Generating Adversarial Examples (Test)\"):\n",
    "            x_np = np.array(x)  # Convert x to a NumPy array\n",
    "            x_adv = attack.generate(x=np.expand_dims(x_np, axis=0))\n",
    "            x_test_attack.append(x_adv[0])  # Convert EagerTensor to NumPy array\n",
    "            y_test_attack.append(y)\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        x_train_attack = np.array(x_train_attack)\n",
    "        y_train_attack = np.array(y_train_attack)\n",
    "        x_test_attack = np.array(x_test_attack)\n",
    "        y_test_attack = np.array(y_test_attack)\n",
    "\n",
    "        # Save the adversarial data\n",
    "        attack_name = attack.__class__.__name__\n",
    "        model_name = \"simple_Conv_28_10_1000\"  # Update with the appropriate model name\n",
    "        save_dir = \"adversarial_data\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        np.savez(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}_train.npz\"), x_train_attack=x_train_attack, y_train_attack=y_train_attack)\n",
    "        np.savez(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}_test.npz\"), x_test_attack=x_test_attack, y_test_attack=y_test_attack)\n",
    "\n",
    "        print(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}\"))\n",
    "\n",
    "        # Calculate accuracy and loss\n",
    "        for x, y in tqdm(zip(x_test_attack, y_test_attack), total=len(y_test_attack), desc=\"Evaluating Adversarial Examples\"):\n",
    "            predictions_adv = np.argmax(classifier.predict(np.expand_dims(x, axis=0)), axis=1)\n",
    "            adv_correct += (predictions_adv == y).sum()\n",
    "            total += 1\n",
    "\n",
    "        _, adv_loss = classifier.model.evaluate(x_test_attack, y_test_attack, verbose=0)\n",
    "        accuracy = adv_correct / total\n",
    "        print(\"Accuracy on adversarial test examples (L_{:.0f}, eps={:.2f}): {:.2f}%. Loss: {:.2f}\".format(norm, epsilon, accuracy * 100, adv_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attack_params = [[2, [0.5, 1, 1.5, 2, 2.5]], [np.inf, [0.05, 0.1, 0.15, 0.2, 0.25]]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf 0.1\n",
      "Generating Adversarial Examples (Train) simple_Conv_28_10_1000_ProjectedGradientDescentTensorFlowV2_0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": "PGD - Batches: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a753ae19d1042f38bd68e8ad93a4cc7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Conv2DBackpropFilter_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[6,441,784] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Conv2DBackpropFilter]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Input \u001B[1;32mIn [35]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     20\u001B[0m y_test_attack \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating Adversarial Examples (Train) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattack_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepsilon\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 22\u001B[0m x_train_attack \u001B[38;5;241m=\u001B[39m \u001B[43mattack\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m y_train_attack \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mcopy(y_train)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m( \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating Adversarial Examples (Test) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattack_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepsilon\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\art\\attacks\\evasion\\projected_gradient_descent\\projected_gradient_descent_tensorflow_v2.py:219\u001B[0m, in \u001B[0;36mProjectedGradientDescentTensorFlowV2.generate\u001B[1;34m(self, x, y, **kwargs)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m rand_init_num \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_random_init)):\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m rand_init_num \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;66;03m# first iteration: use the adversarial examples as they are the only ones we have now\u001B[39;00m\n\u001B[1;32m--> 219\u001B[0m         adv_x[batch_index_1:batch_index_2] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_batch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    220\u001B[0m \u001B[43m            \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_eps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_eps_step\u001B[49m\n\u001B[0;32m    221\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    222\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    223\u001B[0m         adversarial_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_batch(\n\u001B[0;32m    224\u001B[0m             x\u001B[38;5;241m=\u001B[39mbatch, targets\u001B[38;5;241m=\u001B[39mbatch_labels, mask\u001B[38;5;241m=\u001B[39mmask_batch, eps\u001B[38;5;241m=\u001B[39mbatch_eps, eps_step\u001B[38;5;241m=\u001B[39mbatch_eps_step\n\u001B[0;32m    225\u001B[0m         )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\art\\attacks\\evasion\\projected_gradient_descent\\projected_gradient_descent_tensorflow_v2.py:274\u001B[0m, in \u001B[0;36mProjectedGradientDescentTensorFlowV2._generate_batch\u001B[1;34m(self, x, targets, mask, eps, eps_step)\u001B[0m\n\u001B[0;32m    272\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i_max_iter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_iter):\n\u001B[0;32m    273\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_i_max_iter \u001B[38;5;241m=\u001B[39m i_max_iter\n\u001B[1;32m--> 274\u001B[0m     adv_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_tf\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[43madv_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_random_init\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi_max_iter\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m adv_x\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\art\\attacks\\evasion\\projected_gradient_descent\\projected_gradient_descent_tensorflow_v2.py:441\u001B[0m, in \u001B[0;36mProjectedGradientDescentTensorFlowV2._compute_tf\u001B[1;34m(self, x, x_init, y, mask, eps, eps_step, momentum, random_init)\u001B[0m\n\u001B[0;32m    438\u001B[0m     x_adv \u001B[38;5;241m=\u001B[39m x\n\u001B[0;32m    440\u001B[0m \u001B[38;5;66;03m# Get perturbation\u001B[39;00m\n\u001B[1;32m--> 441\u001B[0m perturbation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_perturbation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_adv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecay\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[38;5;66;03m# Apply perturbation and clip\u001B[39;00m\n\u001B[0;32m    444\u001B[0m x_adv \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_perturbation(x_adv, perturbation, eps_step)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\art\\attacks\\evasion\\projected_gradient_descent\\projected_gradient_descent_tensorflow_v2.py:316\u001B[0m, in \u001B[0;36mProjectedGradientDescentTensorFlowV2._compute_perturbation\u001B[1;34m(self, x, y, mask, decay, momentum)\u001B[0m\n\u001B[0;32m    313\u001B[0m tol \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10e-8\u001B[39m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;66;03m# Get gradient wrt loss; invert it if attack is targeted\u001B[39;00m\n\u001B[1;32m--> 316\u001B[0m grad: tf\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_gradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mconstant(\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtargeted), dtype\u001B[38;5;241m=\u001B[39mART_NUMPY_DTYPE\n\u001B[0;32m    318\u001B[0m )\n\u001B[0;32m    320\u001B[0m \u001B[38;5;66;03m# Write summary\u001B[39;00m\n\u001B[0;32m    321\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msummary_writer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\art\\estimators\\classification\\tensorflow.py:1214\u001B[0m, in \u001B[0;36mTensorFlowV2Classifier.loss_gradient\u001B[1;34m(self, x, y, training_mode, **kwargs)\u001B[0m\n\u001B[0;32m   1211\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1212\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loss_object(y_input, predictions)\n\u001B[1;32m-> 1214\u001B[0m gradients \u001B[38;5;241m=\u001B[39m \u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_grad\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1216\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m   1217\u001B[0m     gradients \u001B[38;5;241m=\u001B[39m gradients\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1063\u001B[0m, in \u001B[0;36mGradientTape.gradient\u001B[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[0;32m   1057\u001B[0m   output_gradients \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1058\u001B[0m       composite_tensor_gradient\u001B[38;5;241m.\u001B[39mget_flat_tensors_for_gradients(\n\u001B[0;32m   1059\u001B[0m           output_gradients))\n\u001B[0;32m   1060\u001B[0m   output_gradients \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(x)\n\u001B[0;32m   1061\u001B[0m                       \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m output_gradients]\n\u001B[1;32m-> 1063\u001B[0m flat_grad \u001B[38;5;241m=\u001B[39m \u001B[43mimperative_grad\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimperative_grad\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1064\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1065\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_targets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1066\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_sources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1067\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_gradients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1068\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources_raw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflat_sources_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1069\u001B[0m \u001B[43m    \u001B[49m\u001B[43munconnected_gradients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munconnected_gradients\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1071\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent:\n\u001B[0;32m   1072\u001B[0m   \u001B[38;5;66;03m# Keep track of watched variables before setting tape to None\u001B[39;00m\n\u001B[0;32m   1073\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_watched_variables \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tape\u001B[38;5;241m.\u001B[39mwatched_variables()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001B[0m, in \u001B[0;36mimperative_grad\u001B[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m     64\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     65\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown value for unconnected_gradients: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m unconnected_gradients)\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_TapeGradient\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m     69\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43munconnected_gradients\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:146\u001B[0m, in \u001B[0;36m_gradient_function\u001B[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[0;32m    144\u001B[0m     gradient_name_scope \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m forward_pass_name_scope \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    145\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mname_scope(gradient_name_scope):\n\u001B[1;32m--> 146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgrad_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmock_op\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mout_grads\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    148\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m grad_fn(mock_op, \u001B[38;5;241m*\u001B[39mout_grads)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py:592\u001B[0m, in \u001B[0;36m_Conv2DGrad\u001B[1;34m(op, grad)\u001B[0m\n\u001B[0;32m    573\u001B[0m shape_0, shape_1 \u001B[38;5;241m=\u001B[39m array_ops\u001B[38;5;241m.\u001B[39mshape_n([op\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m0\u001B[39m], op\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m1\u001B[39m]])\n\u001B[0;32m    575\u001B[0m \u001B[38;5;66;03m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001B[39;00m\n\u001B[0;32m    576\u001B[0m \u001B[38;5;66;03m# functions for performance reasons in Eager mode. gen_nn_ops functions take a\u001B[39;00m\n\u001B[0;32m    577\u001B[0m \u001B[38;5;66;03m# `explicit_paddings` parameter, but nn_ops functions do not. So if we were\u001B[39;00m\n\u001B[0;32m    578\u001B[0m \u001B[38;5;66;03m# to use the nn_ops functions, we would have to convert `padding` and\u001B[39;00m\n\u001B[0;32m    579\u001B[0m \u001B[38;5;66;03m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001B[39;00m\n\u001B[0;32m    580\u001B[0m \u001B[38;5;66;03m# in Eager mode.\u001B[39;00m\n\u001B[0;32m    581\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m    582\u001B[0m     gen_nn_ops\u001B[38;5;241m.\u001B[39mconv2d_backprop_input(\n\u001B[0;32m    583\u001B[0m         shape_0,\n\u001B[0;32m    584\u001B[0m         op\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m1\u001B[39m],\n\u001B[0;32m    585\u001B[0m         grad,\n\u001B[0;32m    586\u001B[0m         dilations\u001B[38;5;241m=\u001B[39mdilations,\n\u001B[0;32m    587\u001B[0m         strides\u001B[38;5;241m=\u001B[39mstrides,\n\u001B[0;32m    588\u001B[0m         padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m    589\u001B[0m         explicit_paddings\u001B[38;5;241m=\u001B[39mexplicit_paddings,\n\u001B[0;32m    590\u001B[0m         use_cudnn_on_gpu\u001B[38;5;241m=\u001B[39muse_cudnn_on_gpu,\n\u001B[0;32m    591\u001B[0m         data_format\u001B[38;5;241m=\u001B[39mdata_format),\n\u001B[1;32m--> 592\u001B[0m     \u001B[43mgen_nn_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d_backprop_filter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    594\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshape_1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdilations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdilations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    597\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    598\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    599\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexplicit_paddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexplicit_paddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    600\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cudnn_on_gpu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cudnn_on_gpu\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    601\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    602\u001B[0m ]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:1376\u001B[0m, in \u001B[0;36mconv2d_backprop_filter\u001B[1;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001B[0m\n\u001B[0;32m   1374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   1375\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 1376\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1377\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n\u001B[0;32m   1378\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\handson-ml3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7262\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   7260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[0;32m   7261\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 7262\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: {{function_node __wrapped__Conv2DBackpropFilter_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[6,441,784] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Conv2DBackpropFilter]"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "#attack_params = [[2, [0.5, 1, 1.5, 2, 2.5]], [np.inf, [0.05, 0.1, 0.15, 0.2, 0.25]]]\n",
    "\n",
    "for norm, epsilons in attack_params:\n",
    "    for epsilon in epsilons:\n",
    "        if norm == 2:\n",
    "            attack = FastGradientMethod(estimator=classifier, eps=epsilon, norm=norm)\n",
    "        else:\n",
    "            attack = ProjectedGradientDescentTensorFlowV2(estimator=classifier, eps=epsilon, norm=norm)\n",
    "        print(norm, epsilon)\n",
    "        attack_name = attack.__class__.__name__\n",
    "        model_name = \"simple_Conv_28_10_1000\"  # Update with the appropriate model name\n",
    "        adv_correct = 0\n",
    "        adv_loss = 0\n",
    "        total = 0\n",
    "        x_train_attack = []\n",
    "        y_train_attack = []\n",
    "        x_test_attack = []\n",
    "        y_test_attack = []\n",
    "        print(f\"Generating Adversarial Examples (Train) {model_name}_{attack_name}_{epsilon}\")\n",
    "        x_train_attack = attack.generate(x=x_train)\n",
    "        y_train_attack = np.copy(y_train)\n",
    "\n",
    "        print( f\"Generating Adversarial Examples (Test) {model_name}_{attack_name}_{epsilon}\")\n",
    "        x_test_attack = attack.generate(x=x_test)\n",
    "        y_test_attack = np.copy(y_test)\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        x_train_attack = np.array(x_train_attack)\n",
    "        y_train_attack = np.array(y_train_attack)\n",
    "        x_test_attack = np.array(x_test_attack)\n",
    "        y_test_attack = np.array(y_test_attack)\n",
    "\n",
    "        # Save the adversarial data\n",
    "\n",
    "        save_dir = \"adversarial_data\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        np.savez(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}_train.npz\"), x_train_attack=x_train_attack, y_train_attack=y_train_attack)\n",
    "        np.savez(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}_test.npz\"), x_test_attack=x_test_attack, y_test_attack=y_test_attack)\n",
    "\n",
    "        print(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}\"))\n",
    "\n",
    "        # Calculate accuracy and loss\n",
    "        for x, y in tqdm(zip(x_test_attack, y_test_attack), total=len(y_test_attack), desc=\"Evaluating Adversarial Examples\"):\n",
    "            predictions_adv = np.argmax(classifier.predict(np.expand_dims(x, axis=0)), axis=1)\n",
    "            adv_correct += (predictions_adv == y).sum()\n",
    "            total += 1\n",
    "\n",
    "        _, adv_loss = classifier.model.evaluate(x_test_attack, y_test_attack, verbose=0)\n",
    "        accuracy = adv_correct / total\n",
    "        print(\"Accuracy on adversarial test examples (L_{:.0f}, eps={:.2f}): {:.2f}%. Loss: {:.2f}\".format(norm, epsilon, accuracy * 100, adv_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "#_, adv_loss = classifier.model.evaluate(x_test_attack, y_test_attack, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "attack_params = [ [np.inf, [0.05, 0.15, 0.25]]] #0.1, 0.15, 0.2,\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "x_train_ = x_train[:3000] #\n",
    "y_train_ = y_train[:3000]\n",
    "x_test_ = x_test[:500]\n",
    "y_test_ = y_test[:500]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([5., 9., 5., 4., 9., 4., 3., 6., 0., 5.]),\n array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n <BarContainer object of 10 artists>)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(np.argmax(y_train_, axis=1))\n",
    "plt.hist(np.argmax(y_test_, axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf 0.05\n",
      "Generating Adversarial Examples (Train) simple_Conv_28_10_1000_ProjectedGradientDescentTensorFlowV2_0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": "PGD - Batches: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49f466387dca41bb80d5357ac4e42718"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Adversarial Examples (Test) simple_Conv_28_10_1000_ProjectedGradientDescentTensorFlowV2_0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": "PGD - Batches: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0c950c5dce544b9ad53293eedeb1256"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversarial_data\\simple_Conv_28_10_1000_ProjectedGradientDescentTensorFlowV2_0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Adversarial Examples: 100%|██████████| 50/50 [00:01<00:00, 32.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial test examples (L_inf, eps=0.05): 94.00%. Loss: 0.46\n",
      "inf 0.25\n",
      "Generating Adversarial Examples (Train) simple_Conv_28_10_1000_ProjectedGradientDescentTensorFlowV2_0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": "PGD - Batches: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d541a44eac844a60b99081bc78d53d39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Adversarial Examples (Test) simple_Conv_28_10_1000_ProjectedGradientDescentTensorFlowV2_0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": "PGD - Batches: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a726e38c220c484a9cc91660a2bd76da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversarial_data\\simple_Conv_28_10_1000_ProjectedGradientDescentTensorFlowV2_0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Adversarial Examples: 100%|██████████| 50/50 [00:00<00:00, 79.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial test examples (L_inf, eps=0.25): 0.00%. Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "for norm, epsilons in attack_params:\n",
    "    for epsilon in epsilons:\n",
    "        if norm == 2:\n",
    "            attack = FastGradientMethod(estimator=classifier, eps=epsilon, norm=norm)\n",
    "        else:\n",
    "            attack = ProjectedGradientDescentTensorFlowV2(estimator=classifier, eps=epsilon, norm=norm)\n",
    "        print(norm, epsilon)\n",
    "        attack_name = attack.__class__.__name__\n",
    "        model_name = \"simple_Conv_28_10_1000\"  # Update with the appropriate model name\n",
    "        adv_correct = 0\n",
    "        adv_loss = 0\n",
    "        total = 0\n",
    "        x_train_attack = []\n",
    "        y_train_attack = []\n",
    "        x_test_attack = []\n",
    "        y_test_attack = []\n",
    "        print(f\"Generating Adversarial Examples (Train) {model_name}_{attack_name}_{epsilon}\")\n",
    "        x_train_attack = attack.generate(x=x_train_)\n",
    "        y_train_attack = np.copy(y_train_)\n",
    "\n",
    "        print( f\"Generating Adversarial Examples (Test) {model_name}_{attack_name}_{epsilon}\")\n",
    "        x_test_attack = attack.generate(x=x_test_)\n",
    "        y_test_attack = np.copy(y_test_)\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        x_train_attack = np.array(x_train_attack)\n",
    "        y_train_attack = np.array(y_train_attack)\n",
    "        x_test_attack = np.array(x_test_attack)\n",
    "        y_test_attack = np.array(y_test_attack)\n",
    "\n",
    "        # Save the adversarial data\n",
    "\n",
    "        save_dir = \"adversarial_data\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        np.savez(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}_train.npz\"), x_train_attack=x_train_attack, y_train_attack=y_train_attack)\n",
    "        np.savez(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}_test.npz\"), x_test_attack=x_test_attack, y_test_attack=y_test_attack)\n",
    "\n",
    "        print(os.path.join(save_dir, f\"{model_name}_{attack_name}_{epsilon}\"))\n",
    "\n",
    "        # Calculate accuracy and loss\n",
    "        for x, y in tqdm(zip(x_test_attack, y_test_attack), total=len(y_test_attack), desc=\"Evaluating Adversarial Examples\"):\n",
    "            predictions_adv = np.argmax(classifier.predict(np.expand_dims(x, axis=0)), axis=1)\n",
    "            adv_correct += (predictions_adv == y).sum()\n",
    "            total += 1\n",
    "\n",
    "        _, adv_loss = classifier.model.evaluate(x_test_attack, y_test_attack, verbose=0)\n",
    "        accuracy = adv_correct / total\n",
    "        print(\"Accuracy on adversarial test examples (L_{:.0f}, eps={:.2f}): {:.2f}%. Loss: {:.2f}\".format(norm, epsilon, accuracy * 100, adv_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Smaller test\n",
    "# 350 images -> 1 h 30 min - 2 epsilons"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}